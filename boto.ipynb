{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "import uuid\n",
    "import boto3\n",
    "import re\n",
    "# ReadOnce Object From:\n",
    "# http://stackoverflow.com/questions/30675862/infinite-loop-when-streaming-a-gz-file-from-s3-using-boto\n",
    "class ReadOnce(object):\n",
    "    def __init__(self, k):\n",
    "        self.key = k\n",
    "        self.has_read_once = False\n",
    "\n",
    "    def read(self, size=0):\n",
    "        if self.has_read_once:\n",
    "            return b”\n",
    "        data = self.key.read(size)\n",
    "        if not data:\n",
    "            self.has_read_once = True\n",
    "            return data\n",
    "\n",
    "print(‘Loading IO function’)\n",
    "\n",
    "s3 = boto3.client(‘s3’)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "print(“Received event: ” + json.dumps(event, indent=2))\n",
    "\n",
    "# Get the object from the event and show its content type\n",
    "inbucket = event[‘Records’][0][‘s3’][‘bucket’][‘name’]\n",
    "outbucket = “outlambda”\n",
    "inkey = urllib.unquote_plus(event[‘Records’][0][‘s3’][‘object’][‘key’].encode(‘utf8’))\n",
    "outkey = “out” + inkey\n",
    "try:\n",
    "infile = s3.get_object(Bucket=inbucket, Key=inkey)\n",
    "\n",
    "except Exception as e:\n",
    "print(e)\n",
    "print(‘Error getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.’.format(inkey, bucket))\n",
    "raise e\n",
    "\n",
    "inbody = infile[‘Body’]\n",
    "tmp_path = ‘/tmp/{}{}’.format(uuid.uuid4(), “tmp.txt”)\n",
    "# upload_path = ‘/tmp/resized-{}’.format(key)\n",
    "\n",
    "with open(tmp_path,’w’) as out:\n",
    "unfinished_line = ”\n",
    "bytes=inbody.read(4096)\n",
    "while( bytes ):\n",
    "bytes = unfinished_line + bytes\n",
    "#split on whatever, or use a regex with re.split()\n",
    "lines = bytes.split(‘\\n’)\n",
    "print (“bytes %s” % bytes)\n",
    "unfinished_line = lines.pop()\n",
    "for line in lines:\n",
    "print (“line %s” % line)\n",
    "out.write(line)\n",
    "# yield line\n",
    "bytes=inbody.read(4096)\n",
    "if(unfinished_line):\n",
    "out.write(unfinished_line)\n",
    "#\n",
    "# Upload the file to S3\n",
    "#\n",
    "tmp = open(tmp_path,”r”)\n",
    "try:\n",
    "outfile = s3.put_object(Bucket=outbucket,Key=outkey,Body=tmp)\n",
    "except Exception as e:\n",
    "print(e)\n",
    "print(‘Error putting object {} from bucket {} Body {}. Make sure they exist and your bucket is in the same region as this function.’.format(outkey, outbucket,”tmp.txt”))\n",
    "raise e\n",
    "\n",
    "tmp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
